## 整体流程

1. **启动流程**
   - 通过 `main.py` 启动程序
   - 加载配置文件 `config.yaml`
   - 初始化机器人实例
   - 启动 Web 服务器

2. **核心运行机制**
   ```
   用户 -> 语音输入 -> 语音识别 -> 对话处理 -> 语音合成 -> 语音输出
   ```

3. **详细工作流程**：

   a. **语音输入处理**
   - 通过 `bailing/audio.py` 实时录制用户语音
   - 使用 VAD (语音活动检测) 判断说话开始和结束
   - 保存语音到 `tmp/audio/input/`

   b. **语音识别 (ASR)**
   - `asr_manager.py` 调用语音识别服务
   - 将语音转换为文本

   c. **对话管理**
   - `robot.py` 接收识别后的文本
   - 通过 `chat.py` 处理对话逻辑
   - 调用 `plugins/functions/` 中的相关功能
   - 生成回复文本

   d. **语音合成 (TTS)**
   - `tts_manager.py` 将回复文本转换为语音
   - 保存合成的语音到 `tmp/audio/output/`

   e. **结果输出**
   - 播放合成的语音回复
   - 通过 WebSocket 实时更新对话到网页界面
   - 保存对话记录

4. **插件系统**
   - `function_manager.py` 管理所有功能插件
   - 可以动态调用天气查询、翻译等功能
   - 支持热插拔，可以在运行时添加新功能

5. **Web 界面**
   - `server.py` 提供 Web 服务
   - 实时显示对话内容
   - 支持查看历史对话
   - 提供系统状态监控

## 数据流向
```
语音输入 -> ASR -> 对话处理 -> 插件处理 -> 对话生成 -> TTS -> 语音输出
     ↓                                                           ↓
     └─────────────── WebSocket 实时同步到网页界面 ─────────────┘
```

这种设计的优点：
1. 模块化设计，各组件独立
2. 插件系统便于扩展
3. 实时性好，支持即时对话
4. 提供了可视化界面
5. 完整的日志记录，便于调试 